{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rc1inger/CSC177-DataPreprocessing/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnPsHKbRvlPy"
      },
      "source": [
        "# **Data Preprocessing Project**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CJkQ8uHvlP0"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNXIDpc2vlP1"
      },
      "outputs": [],
      "source": [
        "# Load the dataset and rename columns for clarity\n",
        "data = pd.read_csv('data/heart_disease.csv')\n",
        "data.columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'disease']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdVepy58vlP1"
      },
      "source": [
        "**Drop Duplicates, Handle Missing Values, and Remove Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAGGYrz1vlP1"
      },
      "outputs": [],
      "source": [
        "# Drop the 'disease' column as it's the target variable for prediction\n",
        "data = data.drop(['disease'], axis=1)\n",
        "\n",
        "# Print the shape of the dataset to understand its dimensions\n",
        "print(f'Number of instances = {{data.shape[0]}}')  # Number of rows\n",
        "print(f'Number of attributes = {{data.shape[1]}}')  # Number of columns\n",
        "print(data.head())  # Display the first few rows for a quick overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b6drz10vlP2"
      },
      "outputs": [],
      "source": [
        "# **Modularization: Created a function for duplicate removal**\n",
        "def remove_duplicates(df):\n",
        "    dups = df.duplicated()\n",
        "    print(f'Number of duplicate rows = {{dups.sum()}}')  # Count duplicates\n",
        "    df_cleaned = df.drop_duplicates()\n",
        "    print(f'Number of instances after dropping duplicates = {{df_cleaned.shape[0]}}')  # New row count\n",
        "    return df_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t0AIS_NvlP3"
      },
      "outputs": [],
      "source": [
        "# Remove duplicates from the dataset\n",
        "data2 = remove_duplicates(data)\n",
        "\n",
        "# Replace '?' with NaN to handle missing values properly\n",
        "data3 = data2.replace('?', np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STQo9anBvlP3"
      },
      "outputs": [],
      "source": [
        "# **Handle missing values**\n",
        "def handle_missing_values(df):\n",
        "    for col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    print('Replace missing values with median')\n",
        "    for col in df.columns:\n",
        "        df[col] = df[col].fillna(df[col].median())  # No inplace, reassign the column directly\n",
        "    return df\n",
        "\n",
        "# Handle missing values in the dataset\n",
        "data3 = handle_missing_values(data3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vp_LUeuvlP3"
      },
      "outputs": [],
      "source": [
        "# **Visualize missing values**\n",
        "def visualize_missing_values(df):\n",
        "    missing_values = df.isna().sum()\n",
        "    missing_values = missing_values[missing_values > 0]\n",
        "    if not missing_values.empty:\n",
        "        missing_values.plot(kind='bar', figsize=(10, 5))  # Plot only columns with missing values\n",
        "        plt.title('Missing Values Count')  # Title for the plot\n",
        "        plt.xlabel('Features')  # X-axis label\n",
        "        plt.ylabel('Count')  # Y-axis label\n",
        "        plt.show()  # Display the plot\n",
        "    else:\n",
        "        print(\"No missing values to visualize.\")\n",
        "\n",
        "# Visualize missing values after handling missing data\n",
        "visualize_missing_values(data3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_N8-4qpYvlP3"
      },
      "outputs": [],
      "source": [
        "# **Visualizing potential outliers using boxplots**\n",
        "data3.boxplot(figsize=(20, 3))  # Initial boxplot for visual inspection\n",
        "plt.title('Boxplot of Features Before Outlier Removal')\n",
        "plt.show()  # Display the boxplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxPGzq9_vlP4"
      },
      "outputs": [],
      "source": [
        "# **Remove outliers**\n",
        "def remove_outliers(df):\n",
        "    Z = (df - df.mean()) / df.std()  # Z-score normalization\n",
        "    print(f'Number of rows before removing outliers = {{Z.shape[0]}}')  # Initial row count\n",
        "    Z2 = df.loc[((Z > -3).sum(axis=1) == len(df.columns)) & ((Z <= 3).sum(axis=1) == len(df.columns)), :]\n",
        "    print(f'Number of rows after removing outliers = {{Z2.shape[0]}}')  # Count after outlier removal\n",
        "    return Z2\n",
        "\n",
        "# Remove outliers from the dataset\n",
        "data3 = remove_outliers(data3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puWUdTGZvlP4"
      },
      "source": [
        "**One hot Encoding and Feature Scaling on the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs9XINBCvlP4"
      },
      "outputs": [],
      "source": [
        "# Using Label Encoding for binary columns and One-Hot Encoding for multiclass columns\n",
        "X = data.copy()\n",
        "\n",
        "def encode_categorical(df):\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    le = LabelEncoder()\n",
        "    # Label encode binary categorical columns\n",
        "    df['sex'] = le.fit_transform(df['sex'])\n",
        "    df['fbs'] = le.fit_transform(df['fbs'])\n",
        "    df['exang'] = le.fit_transform(df['exang'])\n",
        "\n",
        "    # One-Hot encode multiclass columns\n",
        "    df = pd.get_dummies(df, columns=['cp', 'restecg', 'slope', 'ca', 'thal'])\n",
        "    return df\n",
        "\n",
        "X_encoded = encode_categorical(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZRqRvb-vlP4"
      },
      "outputs": [],
      "source": [
        "# **Feature scaling**\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data3_scaled = pd.DataFrame(scaler.fit_transform(data3), columns=data3.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_MFJeZjvlP5"
      },
      "outputs": [],
      "source": [
        "# **Visualize cleaned data**\n",
        "def visualize_data(df):\n",
        "    df.boxplot(figsize=(20, 3))  # Size of the plot\n",
        "    plt.title('Boxplot of Features After Cleaning and Scaling')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrBhJ8ltvlP5"
      },
      "outputs": [],
      "source": [
        "# Visualize the cleaned dataset\n",
        "visualize_data(data3_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esZCJrcqvlP6"
      },
      "source": [
        "**Split the Dataset 80% train, 20% test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5tVduTSvlP6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Apply Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "data3_minmax = pd.DataFrame(min_max_scaler.fit_transform(data3), columns=data3.columns)\n",
        "\n",
        "# Display the scaled data\n",
        "print(\"Data after Min-Max Scaling:\\n\", data3_minmax.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA5n9uTEvlP6"
      },
      "outputs": [],
      "source": [
        "# **Split dataset**\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets (80-20 split)\n",
        "train_data, test_data = train_test_split(data3_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# **Calculate mean and standard deviation for both sets**\n",
        "train_mean = train_data.mean()\n",
        "train_std = train_data.std()\n",
        "\n",
        "test_mean = test_data.mean()\n",
        "test_std = test_data.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbnS6KCrvlP6"
      },
      "outputs": [],
      "source": [
        "# Display the mean and standard deviation for training and test sets\n",
        "print(f'Train Mean:\\n{train_mean}')\n",
        "print(f'Train Std:\\n{train_std}')\n",
        "print(f'Test Mean:\\n{test_mean}')\n",
        "print(f'Test Std:\\n{test_std}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaqnyVPCvlP6"
      },
      "source": [
        "**Comparing the training and test values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6CtsRJGvlP6"
      },
      "outputs": [],
      "source": [
        "# Compare the difference between train and test means\n",
        "mean_diff = abs(train_mean - test_mean)\n",
        "std_diff = abs(train_std - test_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSjpKJ5YvlP6"
      },
      "outputs": [],
      "source": [
        "print(f'Mean Differences Between Train and Test:\\n{mean_diff}\\n')\n",
        "print(f'Standard Deviation Differences Between Train and Test:\\n{std_diff}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2RWXjPdvlP6"
      },
      "outputs": [],
      "source": [
        "# Summarize the differences\n",
        "if mean_diff.mean() < 0.1 and std_diff.mean() < 0.1:\n",
        "    print(\"The training and test sets are well-balanced and represent similar distributions.\")\n",
        "else:\n",
        "    print(\"There are some differences between the training and test sets. Further analysis might be required.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}