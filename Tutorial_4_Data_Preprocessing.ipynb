{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYKaN9LRlIqJ"
      },
      "source": [
        "# Module 4: Data Preprocessing\n",
        "\n",
        "The following tutorial contains Python examples for data preprocessing. You should refer to the \"Data\" chapter of the \"Introduction to Data Mining\" book (slides are available at https://www-users.cs.umn.edu/~kumar001/dmbook/index.php) to understand some of the concepts introduced in this tutorial.\n",
        "Data preprocessing consists of a broad set of techniques for cleaning, selecting, and transforming data to improve data mining analysis. Read the step-by-step instructions below carefully. To execute the code, click on the corresponding cell and press the SHIFT-ENTER keys simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm2C1WvhlIqT"
      },
      "source": [
        "## Data Quality Issues\n",
        "\n",
        "Poor data quality can have an adverse effect on data mining. Among the common data quality issues include noise, outliers, missing values, and duplicate data. This section presents examples of Python code to alleviate some of these data quality problems. We begin with an example dataset from the UCI machine learning repository containing information about breast cancer patients. We will first download the dataset using Pandas read_csv() function and display its first 5 data points.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Tu3sX4dUlIqV",
        "outputId": "16136c6c-7303-4fb2-f82f-81922cac15c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances = 699\n",
            "Number of attributes = 10\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clump Thickness</th>\n",
              "      <th>Uniformity of Cell Size</th>\n",
              "      <th>Uniformity of Cell Shape</th>\n",
              "      <th>Marginal Adhesion</th>\n",
              "      <th>Single Epithelial Cell Size</th>\n",
              "      <th>Bare Nuclei</th>\n",
              "      <th>Bland Chromatin</th>\n",
              "      <th>Normal Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
              "0                5                        1                         1   \n",
              "1                5                        4                         4   \n",
              "2                3                        1                         1   \n",
              "3                6                        8                         8   \n",
              "4                4                        1                         1   \n",
              "\n",
              "   Marginal Adhesion  Single Epithelial Cell Size Bare Nuclei  \\\n",
              "0                  1                            2           1   \n",
              "1                  5                            7          10   \n",
              "2                  1                            2           2   \n",
              "3                  1                            3           4   \n",
              "4                  3                            2           1   \n",
              "\n",
              "   Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
              "0                3                1        1      2  \n",
              "1                3                2        1      2  \n",
              "2                3                1        1      2  \n",
              "3                3                7        1      2  \n",
              "4                3                1        1      2  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
        "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
        "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
        "                'Normal Nucleoli', 'Mitoses','Class']\n",
        "\n",
        "data = data.drop(['Sample code'],axis=1)\n",
        "print('Number of instances = %d' % (data.shape[0]))\n",
        "print('Number of attributes = %d' % (data.shape[1]))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9bHK_lolIqd"
      },
      "source": [
        "### Missing Values\n",
        "\n",
        "It is not unusual for an object to be missing one or more attribute values. In some cases, the information was not collected; while in other cases, some attributes are inapplicable to the data instances. This section presents examples on the different approaches for handling missing values.\n",
        "\n",
        "According to the description of the data (https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original), the missing values are encoded as '?' in the original data. Our first task is to convert the missing values to NaNs. We can then count the number of missing values in each column of the data.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDXfaXXwlIqe",
        "outputId": "7bb141d5-3017-42b1-b94b-d6093ea87a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances = 699\n",
            "Number of attributes = 10\n",
            "Number of missing values:\n",
            "\tClump Thickness: 0\n",
            "\tUniformity of Cell Size: 0\n",
            "\tUniformity of Cell Shape: 0\n",
            "\tMarginal Adhesion: 0\n",
            "\tSingle Epithelial Cell Size: 0\n",
            "\tBare Nuclei: 16\n",
            "\tBland Chromatin: 0\n",
            "\tNormal Nucleoli: 0\n",
            "\tMitoses: 0\n",
            "\tClass: 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = data.replace('?',np.NaN)\n",
        "\n",
        "print('Number of instances = %d' % (data.shape[0]))\n",
        "print('Number of attributes = %d' % (data.shape[1]))\n",
        "\n",
        "print('Number of missing values:')\n",
        "for col in data.columns:\n",
        "    print('\\t%s: %d' % (col,data[col].isna().sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96D2bpUklIqf"
      },
      "source": [
        "Observe that only the 'Bare Nuclei' column contains missing values. In the following example, the missing values in the 'Bare Nuclei' column are replaced by the median value of that column. The values before and after replacement are shown for a subset of the data points.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7GOWzdWlIqg",
        "outputId": "b43e70fe-2ef3-479c-8cda-67d6a26d3340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before replacing missing values:\n",
            "20     10\n",
            "21      7\n",
            "22      1\n",
            "23    NaN\n",
            "24      1\n",
            "Name: Bare Nuclei, dtype: object\n",
            "\n",
            "After replacing missing values:\n",
            "20    10.0\n",
            "21     7.0\n",
            "22     1.0\n",
            "23     1.0\n",
            "24     1.0\n",
            "Name: Bare Nuclei, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "data2 = data['Bare Nuclei']\n",
        "\n",
        "print('Before replacing missing values:')\n",
        "print(data2[20:25])\n",
        "\n",
        "data2 = pd.to_numeric(data2, errors='coerce')\n",
        "data2 = data2.fillna(data2.median())\n",
        "\n",
        "print('\\nAfter replacing missing values:')\n",
        "print(data2[20:25])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yt2y0qmlIqh"
      },
      "source": [
        "Instead of replacing the missing values, another common approach is to discard the data points that contain missing values. This can be easily accomplished by applying the dropna() function to the data frame.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjLYBZVslIqi",
        "outputId": "f19a77e2-bae6-437b-ebec-36e1330749c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in original data = 699\n",
            "Number of rows after discarding missing values = 683\n"
          ]
        }
      ],
      "source": [
        "print('Number of rows in original data = %d' % (data.shape[0]))\n",
        "\n",
        "data2 = data.dropna()\n",
        "print('Number of rows after discarding missing values = %d' % (data2.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVyZ-fA5lIqm"
      },
      "source": [
        "### Outliers\n",
        "\n",
        "Outliers are data instances with characteristics that are considerably different from the rest of the dataset. In the example code below, we will draw a boxplot to identify the columns in the table that contain outliers. Note that the values in all columns (except for 'Bare Nuclei') are originally stored as 'int64' whereas the values in the 'Bare Nuclei' column are stored as string objects (since the column initially contains strings such as '?' for representing missing values). Thus, we must  convert the column into numeric values first before creating the boxplot. Otherwise, the column will not be displayed when drawing the boxplot.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "dzklUmaRlIqn",
        "outputId": "008cc646-e375-41ba-b92b-b36b593a173f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "data2 = data.drop(['Class'],axis=1)\n",
        "data2['Bare Nuclei'] = pd.to_numeric(data2['Bare Nuclei'])\n",
        "data2.boxplot(figsize=(20,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6fpKDB-lIqo"
      },
      "source": [
        "The boxplots suggest that only 5 of the columns (Marginal Adhesion, Single Epithetial Cell Size, Bland Cromatin, Normal Nucleoli, and Mitoses) contain abnormally high values. To discard the outliers, we can compute the Z-score for each attribute and remove those instances containing attributes with abnormally high or low Z-score (e.g., if Z > 3 or Z <= -3).\n",
        "\n",
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "The following code shows the results of standardizing the columns of the data. Note that missing values (NaN) are not affected by the standardization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Oyc-wgjAlIqo",
        "outputId": "c341c5bd-199c-48d4-d4c3-708c6a41e00f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clump Thickness</th>\n",
              "      <th>Uniformity of Cell Size</th>\n",
              "      <th>Uniformity of Cell Shape</th>\n",
              "      <th>Marginal Adhesion</th>\n",
              "      <th>Single Epithelial Cell Size</th>\n",
              "      <th>Bare Nuclei</th>\n",
              "      <th>Bland Chromatin</th>\n",
              "      <th>Normal Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.917080</td>\n",
              "      <td>-0.044070</td>\n",
              "      <td>-0.406284</td>\n",
              "      <td>2.519152</td>\n",
              "      <td>0.805662</td>\n",
              "      <td>1.771569</td>\n",
              "      <td>0.640688</td>\n",
              "      <td>0.371049</td>\n",
              "      <td>1.405526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.982519</td>\n",
              "      <td>0.611354</td>\n",
              "      <td>0.603167</td>\n",
              "      <td>0.067638</td>\n",
              "      <td>1.257272</td>\n",
              "      <td>0.948266</td>\n",
              "      <td>1.460910</td>\n",
              "      <td>2.335921</td>\n",
              "      <td>-0.343666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-0.503505</td>\n",
              "      <td>-0.699494</td>\n",
              "      <td>-0.742767</td>\n",
              "      <td>-0.632794</td>\n",
              "      <td>-0.549168</td>\n",
              "      <td>-0.698341</td>\n",
              "      <td>-0.589645</td>\n",
              "      <td>-0.611387</td>\n",
              "      <td>-0.343666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.272227</td>\n",
              "      <td>0.283642</td>\n",
              "      <td>0.603167</td>\n",
              "      <td>-0.632794</td>\n",
              "      <td>-0.549168</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.460910</td>\n",
              "      <td>0.043570</td>\n",
              "      <td>-0.343666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>-1.213798</td>\n",
              "      <td>-0.699494</td>\n",
              "      <td>-0.742767</td>\n",
              "      <td>-0.632794</td>\n",
              "      <td>-0.549168</td>\n",
              "      <td>-0.698341</td>\n",
              "      <td>-0.179534</td>\n",
              "      <td>-0.611387</td>\n",
              "      <td>-0.343666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
              "20         0.917080                -0.044070                 -0.406284   \n",
              "21         1.982519                 0.611354                  0.603167   \n",
              "22        -0.503505                -0.699494                 -0.742767   \n",
              "23         1.272227                 0.283642                  0.603167   \n",
              "24        -1.213798                -0.699494                 -0.742767   \n",
              "\n",
              "    Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
              "20           2.519152                     0.805662     1.771569   \n",
              "21           0.067638                     1.257272     0.948266   \n",
              "22          -0.632794                    -0.549168    -0.698341   \n",
              "23          -0.632794                    -0.549168          NaN   \n",
              "24          -0.632794                    -0.549168    -0.698341   \n",
              "\n",
              "    Bland Chromatin  Normal Nucleoli   Mitoses  \n",
              "20         0.640688         0.371049  1.405526  \n",
              "21         1.460910         2.335921 -0.343666  \n",
              "22        -0.589645        -0.611387 -0.343666  \n",
              "23         1.460910         0.043570 -0.343666  \n",
              "24        -0.179534        -0.611387 -0.343666  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Z = (data2-data2.mean())/data2.std()\n",
        "Z[20:25]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeAWb4m0lIqp"
      },
      "source": [
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "The following code shows the results of discarding columns with Z > 3 or Z <= -3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5YM8wATlIqp",
        "outputId": "db6d53c9-0fb4-40b6-9df1-d04ee00eab01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows before discarding outliers = 699\n",
            "Number of rows after discarding missing values = 632\n"
          ]
        }
      ],
      "source": [
        "print('Number of rows before discarding outliers = %d' % (Z.shape[0]))\n",
        "\n",
        "Z2 = Z.loc[((Z > -3).sum(axis=1)==9) & ((Z <= 3).sum(axis=1)==9),:]\n",
        "print('Number of rows after discarding missing values = %d' % (Z2.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1Y9bwwhlIqq"
      },
      "source": [
        "### Duplicate Data\n",
        "\n",
        "Some datasets, especially those obtained by merging multiple data sources, may contain duplicates or near duplicate instances. The term deduplication is often used to refer to the process of dealing with duplicate data issues.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "In the following example, we first check for duplicate instances in the breast cancer dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "tTxDW_-GlIqq",
        "outputId": "0b70e3d6-bc3d-45d6-afa3-db9a7d1a77d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicate rows = 236\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clump Thickness</th>\n",
              "      <th>Uniformity of Cell Size</th>\n",
              "      <th>Uniformity of Cell Shape</th>\n",
              "      <th>Marginal Adhesion</th>\n",
              "      <th>Single Epithelial Cell Size</th>\n",
              "      <th>Bare Nuclei</th>\n",
              "      <th>Bland Chromatin</th>\n",
              "      <th>Normal Nucleoli</th>\n",
              "      <th>Mitoses</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
              "11                2                        1                         1   \n",
              "28                2                        1                         1   \n",
              "\n",
              "    Marginal Adhesion  Single Epithelial Cell Size Bare Nuclei  \\\n",
              "11                  1                            2           1   \n",
              "28                  1                            2           1   \n",
              "\n",
              "    Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
              "11                2                1        1      2  \n",
              "28                2                1        1      2  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dups = data.duplicated()\n",
        "print('Number of duplicate rows = %d' % (dups.sum()))\n",
        "data.loc[[11,28]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4xOpwZXlIqr"
      },
      "source": [
        "The duplicated() function will return a Boolean array that indicates whether each row is a duplicate of a previous row in the table. The results suggest there are 236 duplicate rows in the breast cancer dataset. For example, the instance with row index 11 has identical attribute values as the instance with row index 28. Although such duplicate rows may correspond to samples for different individuals, in this hypothetical example, we assume that the duplicates are samples taken from the same individual and illustrate below how to remove the duplicated rows.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRurgVZilIqr",
        "outputId": "61885aa1-074a-4fd5-dd8c-b901a9a3265c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows before discarding duplicates = 699\n",
            "Number of rows after discarding duplicates = 463\n"
          ]
        }
      ],
      "source": [
        "print('Number of rows before discarding duplicates = %d' % (data.shape[0]))\n",
        "data2 = data.drop_duplicates()\n",
        "print('Number of rows after discarding duplicates = %d' % (data2.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8HANuFIlIqs"
      },
      "source": [
        "### Shuffling Dataframes\n",
        "It is possible to shuffle.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_-Oll6XSlIqs",
        "outputId": "ecdaf83b-2153-4b74-d99d-6cbfe0d529fb",
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/breast+cancer+wisconsin+original\\\\auto-mpg.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/breast+cancer+wisconsin+original\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m filename_read \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto-mpg.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#np.random.seed(30) # Uncomment this line to get the same shuffle each time\u001b[39;00m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mreindex(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(df\u001b[38;5;241m.\u001b[39mindex))\n",
            "File \u001b[1;32mc:\\Apps\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Apps\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Apps\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Apps\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Apps\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/breast+cancer+wisconsin+original\\\\auto-mpg.csv'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "path = \"data/breast+cancer+wisconsin+original\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read, na_values=['NA','?'])\n",
        "\n",
        "#np.random.seed(30) # Uncomment this line to get the same shuffle each time\n",
        "\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "# use inplace=False\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO0yMaHFlIqt"
      },
      "source": [
        "### Sorting Dataframes\n",
        "It is possible to sort."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "l-5G3hfzlIqt",
        "outputId": "d94122df-ae81-4e10-958e-44eb40ead774"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values(by='name',ascending=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 4: Data Preprocessing\n",
        "\n",
        "The following tutorial contains Python examples for data preprocessing. You should refer to the \"Data\" chapter of the \"Introduction to Data Mining\" book (slides are available at https://www-users.cs.umn.edu/~kumar001/dmbook/index.php) to understand some of the concepts introduced in this tutorial.\n",
        "Data preprocessing consists of a broad set of techniques for cleaning, selecting, and transforming data to improve data mining analysis. Read the step-by-step instructions below carefully. To execute the code, click on the corresponding cell and press the SHIFT-ENTER keys simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Quality Issues\n",
        "\n",
        "Poor data quality can have an adverse effect on data mining. Among the common data quality issues include noise, outliers, missing values, and duplicate data. This section presents examples of Python code to alleviate some of these data quality problems. We begin with an example dataset from the UCI machine learning repository containing information about breast cancer patients. We will first download the dataset using Pandas read_csv() function and display its first 5 data points.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
        "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
        "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
        "                'Normal Nucleoli', 'Mitoses','Class']\n",
        "\n",
        "data = data.drop(['Sample code'],axis=1)\n",
        "print('Number of instances = %d' % (data.shape[0]))\n",
        "print('Number of attributes = %d' % (data.shape[1]))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Missing Values\n",
        "\n",
        "It is not unusual for an object to be missing one or more attribute values. In some cases, the information was not collected; while in other cases, some attributes are inapplicable to the data instances. This section presents examples on the different approaches for handling missing values.\n",
        "\n",
        "According to the description of the data (https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original), the missing values are encoded as '?' in the original data. Our first task is to convert the missing values to NaNs. We can then count the number of missing values in each column of the data.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = data.replace('?',np.NaN)\n",
        "\n",
        "print('Number of instances = %d' % (data.shape[0]))\n",
        "print('Number of attributes = %d' % (data.shape[1]))\n",
        "\n",
        "print('Number of missing values:')\n",
        "for col in data.columns:\n",
        "    print('\\t%s: %d' % (col,data[col].isna().sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe that only the 'Bare Nuclei' column contains missing values. In the following example, the missing values in the 'Bare Nuclei' column are replaced by the median value of that column. The values before and after replacement are shown for a subset of the data points.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data2 = data['Bare Nuclei']\n",
        "\n",
        "print('Before replacing missing values:')\n",
        "print(data2[20:25])\n",
        "\n",
        "data2 = pd.to_numeric(data2, errors='coerce')\n",
        "data2 = data2.fillna(data2.median())\n",
        "\n",
        "print('\\nAfter replacing missing values:')\n",
        "print(data2[20:25])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of replacing the missing values, another common approach is to discard the data points that contain missing values. This can be easily accomplished by applying the dropna() function to the data frame.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Number of rows in original data = %d' % (data.shape[0]))\n",
        "\n",
        "data2 = data.dropna()\n",
        "print('Number of rows after discarding missing values = %d' % (data2.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outliers\n",
        "\n",
        "Outliers are data instances with characteristics that are considerably different from the rest of the dataset. In the example code below, we will draw a boxplot to identify the columns in the table that contain outliers. Note that the values in all columns (except for 'Bare Nuclei') are originally stored as 'int64' whereas the values in the 'Bare Nuclei' column are stored as string objects (since the column initially contains strings such as '?' for representing missing values). Thus, we must  convert the column into numeric values first before creating the boxplot. Otherwise, the column will not be displayed when drawing the boxplot.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "data2 = data.drop(['Class'],axis=1)\n",
        "data2['Bare Nuclei'] = pd.to_numeric(data2['Bare Nuclei'])\n",
        "data2.boxplot(figsize=(20,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The boxplots suggest that only 5 of the columns (Marginal Adhesion, Single Epithetial Cell Size, Bland Cromatin, Normal Nucleoli, and Mitoses) contain abnormally high values. To discard the outliers, we can compute the Z-score for each attribute and remove those instances containing attributes with abnormally high or low Z-score (e.g., if Z > 3 or Z <= -3).\n",
        "\n",
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "The following code shows the results of standardizing the columns of the data. Note that missing values (NaN) are not affected by the standardization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Z = (data2-data2.mean())/data2.std()\n",
        "Z[20:25]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "The following code shows the results of discarding columns with Z > 3 or Z <= -3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Number of rows before discarding outliers = %d' % (Z.shape[0]))\n",
        "\n",
        "Z2 = Z.loc[((Z > -3).sum(axis=1)==9) & ((Z <= 3).sum(axis=1)==9),:]\n",
        "print('Number of rows after discarding missing values = %d' % (Z2.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Duplicate Data\n",
        "\n",
        "Some datasets, especially those obtained by merging multiple data sources, may contain duplicates or near duplicate instances. The term deduplication is often used to refer to the process of dealing with duplicate data issues.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "In the following example, we first check for duplicate instances in the breast cancer dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dups = data.duplicated()\n",
        "print('Number of duplicate rows = %d' % (dups.sum()))\n",
        "data.loc[[11,28]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The duplicated() function will return a Boolean array that indicates whether each row is a duplicate of a previous row in the table. The results suggest there are 236 duplicate rows in the breast cancer dataset. For example, the instance with row index 11 has identical attribute values as the instance with row index 28. Although such duplicate rows may correspond to samples for different individuals, in this hypothetical example, we assume that the duplicates are samples taken from the same individual and illustrate below how to remove the duplicated rows.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Number of rows before discarding duplicates = %d' % (data.shape[0]))\n",
        "data2 = data.drop_duplicates()\n",
        "print('Number of rows after discarding duplicates = %d' % (data2.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Shuffling Dataframes\n",
        "It is possible to shuffle.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read, na_values=['NA','?'])\n",
        "\n",
        "#np.random.seed(30) # Uncomment this line to get the same shuffle each time\n",
        "\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "# use inplace=False\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sorting Dataframes\n",
        "It is possible to sort."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sort_values(by='name',ascending=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"The first car is: {}\".format(df['name'].iloc[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"The first car is: {}\".format(df['name'].loc[0]))\n",
        "\n",
        "\n",
        "#loc gets rows (or columns) with particular labels from the index.\n",
        "#iloc gets rows (or columns) at particular positions in the index (so it only takes integers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving a Dataframe\n",
        "\n",
        "The following code performs a shuffle and then saves a new copy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "filename_write = os.path.join(path,\"auto-mpg-shuffle.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.to_csv(filename_write,index=False)   # Specify index = false to not write row numbers\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dropping Fields\n",
        "\n",
        "Some fields are of no value to the neural network and can be dropped.  The following code removes the name column from the MPG dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "print(\"Before drop: {}\".format(df.columns))\n",
        "df.drop('name', axis=1, inplace=True)\n",
        "print(\"After drop: {}\".format(df.columns))\n",
        "df[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculated Fields\n",
        "\n",
        "It is possible to add new fields to the dataframe that are calculated from the other fields.  We can create a new column that gives the weight in kilograms.  The equation to calculate a metric weight, given a weight in pounds is:\n",
        "\n",
        "$ m_{(kg)} = m_{(lb)} \\times 0.45359237 $\n",
        "\n",
        "This can be used with the following Python code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "df.insert(1,'weight_kg',(df['weight']*0.45359237).astype(int))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Normalization\n",
        "\n",
        "A normalization allows numbers to be put in a standard form so that two values can easily be compared. One very common machine learning normalization is the Z-Score:\n",
        "\n",
        "$z = {x- \\mu \\over \\sigma} $\n",
        "\n",
        "To calculate the Z-Score you need to also calculate the mean($\\mu$) and the standard deviation ($\\sigma$).  The mean is calculated as follows:\n",
        "\n",
        "$\\mu = \\bar{x} = \\frac{x_1+x_2+\\cdots +x_n}{n}$\n",
        "\n",
        "The standard deviation is calculated as follows:\n",
        "\n",
        "$\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}, {\\rm \\ \\ where\\ \\ } \\mu = \\frac{1}{N} \\sum_{i=1}^N x_i$\n",
        "\n",
        "The following Python code ***replaces the mpg with a z-score***.  Cars with average MPG will be near zero, above zero is above average, and below zero is below average.  Z-Scores above/below -3/3 are very rare, these are outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "df['mpg'] = zscore(df['mpg'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Missing Values\n",
        "\n",
        "You can also simply drop any rows with any NA values.  Another common practice is to replace missing values with the median value for that column. The following code replaces any NA values in horsepower with the median:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "med = df['horsepower'].median()\n",
        "df['horsepower'] = df['horsepower'].fillna(med)\n",
        "\n",
        "# df = df.dropna() # you can also simply drop NA values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Concatenating Rows and Columns\n",
        "Rows and columns can be concatenated together to form new data frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new dataframe from name and horsepower\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "col_horsepower = df['horsepower']\n",
        "col_name = df['name']\n",
        "result = pd.concat([col_name,col_horsepower],axis=1)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new dataframe from name and horsepower, but this time by row\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "col_horsepower = df['horsepower']\n",
        "col_name = df['name']\n",
        "result = pd.concat([col_name,col_horsepower])\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helpful Functions for Tensorflow (Little Gems)\n",
        "\n",
        "The following functions will be used with TensorFlow to help preprocess the data.  \n",
        "\n",
        "### They allow you to build the feature vector in the format that TensorFlow expects from raw data.\n",
        "\n",
        "(1) Encoding data:\n",
        "\n",
        "* **encode_text_dummy** - Encode text fields as numeric, such as the iris species as a single field for each class.  Three classes would become \"0,0,1\" \"0,1,0\" and \"1,0,0\". Encode non-target features this way. used when the data is part of input ***(one hot encoding)***\n",
        "* **encode_text_index** - Encode text fields to numeric, such as the iris species as a single numeric field as \"0\" \"1\" and \"2\".  Encode the target field for a classification this way.  used when data is part of output            ***(label encoding)***\n",
        "\n",
        "(2) Normalizing data:\n",
        "\n",
        "* **encode_numeric_zscore** - Encode numeric values as a z-score.  Neural networks deal well with \"normalized\" fields only.\n",
        "* **encode_numeric_range** - Encode a column to a range between the given normalized_low and normalized_high.\n",
        "\n",
        "(3) Dealing with missing data:\n",
        "\n",
        "* **missing_median** - Fill all missing values with the median value.\n",
        "\n",
        "\n",
        "(4) Removing outliers:\n",
        "\n",
        "* **remove_outliers**  - Remove outliers in a certain column with a value beyond X times SD\n",
        "\n",
        "\n",
        "(5) Creating the feature vector and target vector that *** Tensorflow needs***:\n",
        "\n",
        "* **to_xy** - ***Once all fields are encoded to numeric, this function can provide the x and y matrixes that TensorFlow needs to fit the neural network with data.***\n",
        "\n",
        "(6) Other utility functions:\n",
        "\n",
        "* **hms_string** - Print out an elapsed time string.\n",
        "* **chart_regression** - Display a chart to show how well a regression performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import collections.abc\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column.\n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, collections.abc.Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) * (normalized_high - normalized_low) + normalized_low\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Examples of label encoding, one hot encoding,  and creating X/Y for TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"iris.csv\",na_values=['NA','?']) #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encode_text_index(df,\"species\")   # label encoding\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"iris.csv\",na_values=['NA','?']) #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "\n",
        "encode_text_dummy(df,\"species\")   # One hot encoding\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make sure you encode the lables first before you call to_xy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"iris.csv\",na_values=['NA','?']) #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "\n",
        "encode_text_index(df,\"species\")    # encoding first before you call to_xy()\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x,y = to_xy(df,\"species\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example of Deal with Missing Values and Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "# Handle mising values in horsepower\n",
        "missing_median(df, 'horsepower')\n",
        "#df.drop('name', 1,inplace=True)\n",
        "\n",
        "# Drop outliers in horsepower\n",
        "print(\"Length before MPG outliers dropped: {}\".format(len(df)))\n",
        "remove_outliers(df,'mpg',2)\n",
        "print(\"Length after MPG outliers dropped: {}\".format(len(df)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Validation\n",
        "\n",
        "The machine learning model will learn from the training data, but ultimately be evaluated based on the validation data.\n",
        "\n",
        "* **Training Data** - **In Sample Data** - The data that the machine learning model was fit to/created from.\n",
        "* **Validation Data** - **Out of Sample Data** - The data that the machine learning model is evaluated upon after it is fit to the training data.\n",
        "\n",
        "There are two predominant means of dealing with training and validation data:\n",
        "\n",
        "* **Training/Test Split** - The data are split according to some ratio between a training and validation (hold-out) set.  Common ratios are 80% training and 20% validation.\n",
        "* **K-Fold Cross Validation** - The data are split into a number of folds and models.  Because a number of models equal to the folds is created out-of-sample predictions can be generated for the entire dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training/Test Split\n",
        "\n",
        "The code below performs a split of the MPG data into a training and validation set.  The training set uses 80% of the data and the test(validation) set uses 20%.\n",
        "\n",
        "The following image shows how a model is trained on 80% of the data and then validated against the remaining 20%.\n",
        "\n",
        "![Training and Validation](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_1_train_val.png \"Training and Validation\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename = os.path.join(path,\"iris.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename,na_values=['NA','?'])\n",
        "\n",
        "df[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['encoded_species'] = le.fit_transform(df['species'])\n",
        "\n",
        "df[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into train/test\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']], df['encoded_species'], test_size=0.25, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aggregation\n",
        "\n",
        "Data aggregation is a preprocessing task where the values of two or more objects are combined into a single object. The motivation for aggregation includes (1) reducing the size of data to be processed, (2) changing the granularity of analysis (from fine-scale to coarser-scale), and (3) improving the stability of the data.\n",
        "\n",
        "In the example below, we will use the daily precipitation time series data for a weather station located at Detroit Metro Airport. The raw data was obtained from the Climate Data Online website (https://www.ncdc.noaa.gov/cdo-web/). The daily precipitation time series will be compared against its monthly values.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "The code below will load the precipitation time series data and draw a line plot of its daily time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "daily = pd.read_csv('DTW_prec.csv', header='infer') #The file is available to download from canvas in path Files --> Lab Help --> Labs\n",
        "daily.index = pd.to_datetime(daily['DATE'])\n",
        "daily = daily['PRCP']\n",
        "ax = daily.plot(kind='line',figsize=(15,3))\n",
        "ax.set_title('Daily Precipitation (variance = %.4f)' % (daily.var()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "daily"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe that the daily time series appear to be quite chaotic and varies significantly from one time step to another. The time series can be grouped and aggregated by month to obtain the total monthly precipitation values. The resulting time series appears to vary more smoothly compared to the daily time series.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "monthly = daily.groupby(pd.Grouper(freq='M')).sum()\n",
        "ax = monthly.plot(kind='line',figsize=(15,3))\n",
        "ax.set_title('Monthly Precipitation (variance = %.4f)' % (monthly.var()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the example below, the daily precipitation time series are grouped and aggregated by year to obtain the annual precipitation values.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "annual = daily.groupby(pd.Grouper(freq='Y')).sum()\n",
        "ax = annual.plot(kind='line',figsize=(15,3))\n",
        "ax.set_title('Annual Precipitation (variance = %.4f)' % (annual.var()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sampling\n",
        "\n",
        "Sampling is an approach commonly used to facilitate (1) data reduction for exploratory data analysis and scaling up algorithms to big data applications and (2) quantifying uncertainties due to varying data distributions. There are various methods available for data sampling, such as sampling without replacement, where each selected instance is removed from the dataset, and sampling with replacement, where each selected instance is not removed, thus allowing it to be selected more than once in the sample.\n",
        "\n",
        "In the example below, we will apply sampling with replacement and without replacement to the breast cancer dataset obtained from the UCI machine learning repository.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "We initially display the first five records of the table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following code, a sample of size 3 is randomly selected (without replacement) from the original data.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = data.sample(n=3)\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next example, we randomly select 1% of the data (without replacement) and display the selected samples. The random_state argument of the function specifies the seed value of the random number generator.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = data.sample(frac=0.01, random_state=1)\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we perform a sampling with replacement to create a sample whose size is equal to 1% of the entire data. You should be able to observe duplicate instances in the sample by increasing the sample size.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = data.sample(frac=0.01, replace=True, random_state=1)\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Discretization\n",
        "\n",
        "Discretization is a data preprocessing step that is often used to transform a continuous-valued attribute to a categorical attribute. The example below illustrates two simple but widely-used unsupervised discretization methods (equal width and equal depth) applied to the 'Clump Thickness' attribute of the breast cancer dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we plot a histogram that shows the distribution of the attribute values. The value_counts() function can also be applied to count the frequency of each attribute value.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['Clump Thickness'].hist(bins=10)\n",
        "data['Clump Thickness'].value_counts(sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the equal width method, we can apply the cut() function to discretize the attribute into 4 bins of similar interval widths. The value_counts() function can be used to determine the number of instances in each bin.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bins = pd.cut(data['Clump Thickness'],4)\n",
        "bins.value_counts(sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the equal frequency method, the qcut() function can be used to partition the values into 4 bins such that each bin has nearly the same number of instances.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bins = pd.qcut(data['Clump Thickness'],4)\n",
        "bins.value_counts(sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Principal Component Analysis\n",
        "\n",
        "Principal component analysis (PCA) is a classical method for reducing the number of attributes in the data by projecting the data from its original high-dimensional space into a lower-dimensional space. The new attributes (also known as components) created by PCA have the following properties: (1) they are linear combinations of the original attributes, (2) they are orthogonal (perpendicular) to each other, and (3) they capture the maximum amount of variation in the data.\n",
        "\n",
        "The example below illustrates the application of PCA to an image dataset. There are 16 RGB files, each of which has a size of 111 x 111 pixels. The example code below will read each image file and convert the RGB image into a 111 x 111 x 3 = 36963 feature values. This will create a data matrix of size 16 x 36963.    \n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "\n",
        "numImages = 16\n",
        "fig = plt.figure(figsize=(7,7))\n",
        "imgData = np.zeros(shape=(numImages,36963))\n",
        "\n",
        "for i in range(1,numImages+1):\n",
        "    filename = 'pics/Picture'+str(i)+'.jpg' #The file is available to download from canvas in path Files --> Lab Help --> Labs\n",
        "    img = mpimg.imread(filename)\n",
        "    ax = fig.add_subplot(4,4,i)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    ax.set_title(str(i))\n",
        "    imgData[i-1] = np.array(img.flatten()).reshape(1,img.shape[0]*img.shape[1]*img.shape[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using PCA, the data matrix is projected to its first two principal components. The projected values of the original image data are stored in a pandas DataFrame object named projected.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "numComponents = 2\n",
        "pca = PCA(n_components=numComponents)\n",
        "pca.fit(imgData)\n",
        "\n",
        "projected = pca.transform(imgData)\n",
        "projected = pd.DataFrame(projected,columns=['pc1','pc2'],index=range(1,numImages+1))\n",
        "projected['food'] = ['burger', 'burger','burger','burger','drink','drink','drink','drink',\n",
        "                      'pasta', 'pasta', 'pasta', 'pasta', 'chicken', 'chicken', 'chicken', 'chicken']\n",
        "projected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we draw a scatter plot to display the projected values. Observe that the images of burgers, drinks, and pastas  are all projected to the same region. However, the images for fried chicken (shown as black squares in the diagram) are harder to discriminate.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "colors = {'burger':'b', 'drink':'r', 'pasta':'g', 'chicken':'k'}\n",
        "markerTypes = {'burger':'+', 'drink':'x', 'pasta':'o', 'chicken':'s'}\n",
        "\n",
        "for foodType in markerTypes:\n",
        "    d = projected[projected['food']==foodType]\n",
        "    plt.scatter(d['pc1'],d['pc2'],c=colors[foodType],s=60,marker=markerTypes[foodType])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Selection Techniques\n",
        "The goal of feature selection techniques in machine learning is to find the best set of features that allows one to build optimized models of studied phenomena.\n",
        "\n",
        "### Information Gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "df = pd.read_csv('Admission_Predict_Ver1.1.csv') #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data --> Linear_Regression_data\n",
        "X = df.iloc[:,1:-1]\n",
        "Y = df.iloc[:,-1]\n",
        "importances = mutual_info_regression(X, Y)\n",
        "feat_importances = pd.Series(importances,X.columns)\n",
        "feat_importances.plot(kind='barh',color = 'teal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chi-square Test\n",
        "The Chi-square test is used for categorical features in a dataset. We calculate Chi-square between each feature and the target and select the desired number of features with the best Chi-square scores. In order to correctly apply the chi-squared to test the relation between various features in the dataset and the target variable, the following conditions have to be met: the variables have to be categorical, sampled independently, and values should have an expected frequency greater than 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_Cat = X.astype(int)\n",
        "le = LabelEncoder()\n",
        "chi2_features = SelectKBest(chi2, k = 3)\n",
        "Y = le.fit_transform(Y)\n",
        "X_kbest_features = chi2_features.fit_transform(X_Cat,Y)\n",
        "\n",
        "print('Original feature number:', X_Cat.shape[1])\n",
        "print('Reduced feature number: ',X_kbest_features.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation Coefficient\n",
        "Correlation is a measure of the linear relationship between 2 or more variables. Through correlation, we can predict one variable from the other. The logic behind using correlation for feature selection is that good variables correlate highly with the target. Furthermore, variables should be correlated with the target but uncorrelated among themselves.\n",
        "\n",
        "If two variables are correlated, we can predict one from the other. Therefore, if two features are correlated, the model only needs one, as the second does not add additional information. We will use the Pearson Correlation here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "cor = df.corr()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cor,annot= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variance Threshold\n",
        "\n",
        "The variance threshold is a simple baseline approach to feature selection. It removes all features whose variance doesnt meet some threshold. By default, it removes all zero-variance features, i.e., features with the same value in all samples. We assume that features with a higher variance may contain more useful information, but note that we are not taking the relationship between feature variables or feature and target variables into account, which is one of the drawbacks of filter methods.\n",
        "\n",
        "The get_support returns a Boolean vector where True means the variable does not have zero variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X = globals()[\"X\"]\n",
        "\n",
        "\n",
        "v_threshold = VarianceThreshold(threshold = 0)\n",
        "v_threshold.fit(X)\n",
        "v_threshold.get_support()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mean Absolute Difference (MAD)\n",
        "The mean absolute difference (MAD) computes the absolute difference from the mean value. The main difference between the variance and MAD measures is the absence of the square in the latter. The MAD, like the variance, is also a scaled variant. This means that the higher the MAD, the higher the discriminatory power."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_abs_diff = np.sum(np.abs(X -np.mean(X, axis=0)), axis=0)/X.shape[0]\n",
        "\n",
        "plt.bar(np.arange(X.shape[1]),mean_abs_diff,color = 'teal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backward Elimination Techniques\n",
        "## Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing as prepr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import dataset and do necessary changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('Admission_Predict_Ver1.1.csv') #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data --> Linear_Regression_data\n",
        "print('Shape:{}'.format(df.shape))\n",
        "print(df.head(10))\n",
        "print(df.describe())\n",
        "df.columns = [x.replace(' ', '').replace('.', '').lower() for x in list(df)] #converts columnnames to lower single words\n",
        "del df['serialno']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.boxplot(showbox=True, figsize=(10,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Standardizing the entire dataset using Min-Max scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = list(df)\n",
        "scaler = prepr.MinMaxScaler()\n",
        "scaled_df = scaler.fit_transform(df)\n",
        "scaled_df = pd.DataFrame(scaled_df, columns=cols)\n",
        "print(scaled_df.head(10))\n",
        "print(scaled_df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pairplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a scatter plot of all the attributes on both x and y axes. 'chanceofadmit' is the dependent variable and the plot clearly shows that there are few attributes that have a linear relation with the dependent attribute. So we can move ahead with linear regression.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.pairplot(scaled_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating X and Y for the linear regression equation (Y = a  + $X_{1}$ + $X_{2}$ + ... + $X_{n}$) where Y is the dependent variable and Xs are the independent variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = list(scaled_df)\n",
        "X = scaled_df.iloc[:, :-1]\n",
        "y = scaled_df[cols[-1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using statsmodels provided Linear Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OLS is the function used to create a linear model. This model defines the linear regression formula as\n",
        "Y = $aX_{0}$ + $X_{1}$ + $X_{2}$ + ... + $X_{n}$.\n",
        "\n",
        "So create a new attribute with all ones and append it to the start of the dataframe. This will serve as $X_{0}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.append(arr=np.ones([len(scaled_df.index), 1]).astype(int), values=X, axis=1)\n",
        "options = X[:, [0, 1, 2, 3, 4, 5, 6, 7]]\n",
        "lm_be = sm.OLS(endog=y, exog=options).fit()\n",
        "print(lm_be.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove attribute 4 (sop) as it has the highest p-value and rewrite the formula\n",
        "options= X[:, [0, 1, 2, 3, 5, 6, 7]]\n",
        "lm_be = sm.OLS(endog=y, exog=options).fit()\n",
        "lm_be.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove attribute 3 (universityrating) as it has the highest p-value and rewrite the formula\n",
        "options = X[:, [0, 1, 2, 5, 6, 7]]\n",
        "lm_be = sm.OLS(endog=y, exog=options).fit()\n",
        "lm_be.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create train and test set from the attributes that are not eliminated by backward elimination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(options, y, test_size=0.2, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a regular Linear Regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lm = LinearRegression().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Predict\n",
        "y_pred = lm.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "print(final_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
        "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_Bdv09plIqu",
        "outputId": "11cdcbb5-75be-4f71-9aa7-ba99e1774ccc"
      },
      "outputs": [],
      "source": [
        "print(\"The first car is: {}\".format(df['name'].iloc[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypNXRhRplIqu",
        "outputId": "1ad07966-de2d-4d77-df11-08b4189dba09"
      },
      "outputs": [],
      "source": [
        "print(\"The first car is: {}\".format(df['name'].loc[0]))\n",
        "\n",
        "\n",
        "#loc gets rows (or columns) with particular labels from the index.\n",
        "#iloc gets rows (or columns) at particular positions in the index (so it only takes integers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXnYrj7mlIqu"
      },
      "source": [
        "### Saving a Dataframe\n",
        "\n",
        "The following code performs a shuffle and then saves a new copy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_igYBO9lIqv",
        "outputId": "73d6e125-7d53-441a-dcd0-5030c937a0f1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "filename_write = os.path.join(path,\"auto-mpg-shuffle.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.to_csv(filename_write,index=False)   # Specify index = false to not write row numbers\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA5q-ZaBlIqv"
      },
      "source": [
        "### Dropping Fields\n",
        "\n",
        "Some fields are of no value to the neural network and can be dropped.  The following code removes the name column from the MPG dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "GUz04rXplIqw",
        "outputId": "a7e36f49-0ef2-4f91-d049-c665474804e3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "print(\"Before drop: {}\".format(df.columns))\n",
        "df.drop('name', axis=1, inplace=True)\n",
        "print(\"After drop: {}\".format(df.columns))\n",
        "df[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqP2ZnmOlIqw"
      },
      "source": [
        "### Calculated Fields\n",
        "\n",
        "It is possible to add new fields to the dataframe that are calculated from the other fields.  We can create a new column that gives the weight in kilograms.  The equation to calculate a metric weight, given a weight in pounds is:\n",
        "\n",
        "$ m_{(kg)} = m_{(lb)} \\times 0.45359237 $\n",
        "\n",
        "This can be used with the following Python code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vh-OoqFglIqw",
        "outputId": "4307f7c6-5144-4266-ee66-0397f171fe9a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "df.insert(1,'weight_kg',(df['weight']*0.45359237).astype(int))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MleTIYClIqx"
      },
      "source": [
        "### Feature Normalization\n",
        "\n",
        "A normalization allows numbers to be put in a standard form so that two values can easily be compared. One very common machine learning normalization is the Z-Score:\n",
        "\n",
        "$z = {x- \\mu \\over \\sigma} $\n",
        "\n",
        "To calculate the Z-Score you need to also calculate the mean($\\mu$) and the standard deviation ($\\sigma$).  The mean is calculated as follows:\n",
        "\n",
        "$\\mu = \\bar{x} = \\frac{x_1+x_2+\\cdots +x_n}{n}$\n",
        "\n",
        "The standard deviation is calculated as follows:\n",
        "\n",
        "$\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}, {\\rm \\ \\ where\\ \\ } \\mu = \\frac{1}{N} \\sum_{i=1}^N x_i$\n",
        "\n",
        "The following Python code ***replaces the mpg with a z-score***.  Cars with average MPG will be near zero, above zero is above average, and below zero is below average.  Z-Scores above/below -3/3 are very rare, these are outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cWWu8jDQlIqx",
        "outputId": "68137f58-296f-494f-9db0-91279ab75290",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "df['mpg'] = zscore(df['mpg'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWFpGv0-lIqy"
      },
      "source": [
        "### Missing Values\n",
        "\n",
        "You can also simply drop any rows with any NA values.  Another common practice is to replace missing values with the median value for that column. The following code replaces any NA values in horsepower with the median:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M3rksjJlIqy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "med = df['horsepower'].median()\n",
        "df['horsepower'] = df['horsepower'].fillna(med)\n",
        "\n",
        "# df = df.dropna() # you can also simply drop NA values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoQdILdklIqz"
      },
      "source": [
        "### Concatenating Rows and Columns\n",
        "Rows and columns can be concatenated together to form new data frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BLJaH0YXlIqz",
        "outputId": "86ceb3d1-700a-4b1f-e0ee-6cd99f2a4ed9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe from name and horsepower\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "col_horsepower = df['horsepower']\n",
        "col_name = df['name']\n",
        "result = pd.concat([col_name,col_horsepower],axis=1)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKzYO1oSlIq0",
        "outputId": "70359e00-83d0-4d69-d9c8-acaa46f7dfc2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create a new dataframe from name and horsepower, but this time by row\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "col_horsepower = df['horsepower']\n",
        "col_name = df['name']\n",
        "result = pd.concat([col_name,col_horsepower])\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "VjX7tqB7lIq0"
      },
      "source": [
        "# Helpful Functions for Tensorflow (Little Gems)\n",
        "\n",
        "The following functions will be used with TensorFlow to help preprocess the data.  \n",
        "\n",
        "### They allow you to build the feature vector in the format that TensorFlow expects from raw data.\n",
        "\n",
        "(1) Encoding data:\n",
        "\n",
        "* **encode_text_dummy** - Encode text fields as numeric, such as the iris species as a single field for each class.  Three classes would become \"0,0,1\" \"0,1,0\" and \"1,0,0\". Encode non-target features this way. used when the data is part of input ***(one hot encoding)***\n",
        "* **encode_text_index** - Encode text fields to numeric, such as the iris species as a single numeric field as \"0\" \"1\" and \"2\".  Encode the target field for a classification this way.  used when data is part of output            ***(label encoding)***\n",
        "\n",
        "(2) Normalizing data:\n",
        "\n",
        "* **encode_numeric_zscore** - Encode numeric values as a z-score.  Neural networks deal well with \"normalized\" fields only.\n",
        "* **encode_numeric_range** - Encode a column to a range between the given normalized_low and normalized_high.\n",
        "\n",
        "(3) Dealing with missing data:\n",
        "\n",
        "* **missing_median** - Fill all missing values with the median value.\n",
        "\n",
        "\n",
        "(4) Removing outliers:\n",
        "\n",
        "* **remove_outliers**  - Remove outliers in a certain column with a value beyond X times SD\n",
        "\n",
        "\n",
        "(5) Creating the feature vector and target vector that *** Tensorflow needs***:\n",
        "\n",
        "* **to_xy** - ***Once all fields are encoded to numeric, this function can provide the x and y matrixes that TensorFlow needs to fit the neural network with data.***\n",
        "\n",
        "(6) Other utility functions:\n",
        "\n",
        "* **hms_string** - Print out an elapsed time string.\n",
        "* **chart_regression** - Display a chart to show how well a regression performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "dMjtKX1slIrL"
      },
      "outputs": [],
      "source": [
        "import collections.abc\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = \"{}-{}\".format(name, x)\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "\n",
        "# Encode a numeric column as zscores\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the median\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "\n",
        "\n",
        "# Convert all missing values in the specified column to the default\n",
        "def missing_default(df, name, default_value):\n",
        "    df[name] = df[name].fillna(default_value)\n",
        "\n",
        "\n",
        "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    # find out the type of the target column.\n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if isinstance(target_type, collections.abc.Sequence) else target_type\n",
        "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
        "\n",
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "\n",
        "# Regression chart.\n",
        "def chart_regression(pred,y,sort=True):\n",
        "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
        "    if sort:\n",
        "        t.sort_values(by=['y'],inplace=True)\n",
        "    a = plt.plot(t['y'].tolist(),label='expected')\n",
        "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
        "    plt.ylabel('output')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Remove all rows where the specified column is +/- sd standard deviations\n",
        "def remove_outliers(df, name, sd):\n",
        "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
        "    df.drop(drop_rows, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "# Encode a column to a range between normalized_low and normalized_high.\n",
        "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
        "                         data_low=None, data_high=None):\n",
        "    if data_low is None:\n",
        "        data_low = min(df[name])\n",
        "        data_high = max(df[name])\n",
        "\n",
        "    df[name] = ((df[name] - data_low) / (data_high - data_low)) * (normalized_high - normalized_low) + normalized_low\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "qTox3xG8lIrL"
      },
      "source": [
        "### Examples of label encoding, one hot encoding,  and creating X/Y for TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "hidden": true,
        "id": "I-cnCBh0lIrM",
        "outputId": "9512a7b8-6676-479b-be56-d30d5f7a6613"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"iris.csv\",na_values=['NA','?']) #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "hidden": true,
        "id": "-59ni55glIrM",
        "outputId": "f25ab588-1874-46a5-82ea-9eef27fe3575"
      },
      "outputs": [],
      "source": [
        "encode_text_index(df,\"species\")   # label encoding\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "hidden": true,
        "id": "QG_66JlZlIrM",
        "outputId": "1ef55b08-8641-469c-cd4d-721d5d05a6ad"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"iris.csv\",na_values=['NA','?']) #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "\n",
        "encode_text_dummy(df,\"species\")   # One hot encoding\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "UDDww38YlIrM"
      },
      "source": [
        "### Make sure you encode the lables first before you call to_xy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "hidden": true,
        "id": "G48N9hg_lIrN",
        "outputId": "d0a6092a-3bde-4b95-bc82-1d25bfbc07cb"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"iris.csv\",na_values=['NA','?']) #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "\n",
        "encode_text_index(df,\"species\")    # encoding first before you call to_xy()\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "QI5jC0uulIrN"
      },
      "outputs": [],
      "source": [
        "x,y = to_xy(df,\"species\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "7mEdflVIlIrN",
        "outputId": "8fe69dab-a4ca-49ae-c304-6aa5da43da3e"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "JuHwd97YlIrN",
        "outputId": "6141ab8d-36e9-4a8f-e242-816051300755"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "WDL-XFmKlIrO"
      },
      "source": [
        "## Example of Deal with Missing Values and Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "d6CrVVGzlIrO",
        "outputId": "458cd143-6a91-4fae-89ae-3993411d419b"
      },
      "outputs": [],
      "source": [
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename_read = os.path.join(path,\"auto-mpg.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
        "\n",
        "# Handle mising values in horsepower\n",
        "missing_median(df, 'horsepower')\n",
        "#df.drop('name', 1,inplace=True)\n",
        "\n",
        "# Drop outliers in horsepower\n",
        "print(\"Length before MPG outliers dropped: {}\".format(len(df)))\n",
        "remove_outliers(df,'mpg',2)\n",
        "print(\"Length after MPG outliers dropped: {}\".format(len(df)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "heading_collapsed": true,
        "hidden": true,
        "id": "lctniw2QlIrO"
      },
      "source": [
        "## Training and Validation\n",
        "\n",
        "The machine learning model will learn from the training data, but ultimately be evaluated based on the validation data.\n",
        "\n",
        "* **Training Data** - **In Sample Data** - The data that the machine learning model was fit to/created from.\n",
        "* **Validation Data** - **Out of Sample Data** - The data that the machine learning model is evaluated upon after it is fit to the training data.\n",
        "\n",
        "There are two predominant means of dealing with training and validation data:\n",
        "\n",
        "* **Training/Test Split** - The data are split according to some ratio between a training and validation (hold-out) set.  Common ratios are 80% training and 20% validation.\n",
        "* **K-Fold Cross Validation** - The data are split into a number of folds and models.  Because a number of models equal to the folds is created out-of-sample predictions can be generated for the entire dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Q5nxQYl9lIrO"
      },
      "source": [
        "### Training/Test Split\n",
        "\n",
        "The code below performs a split of the MPG data into a training and validation set.  The training set uses 80% of the data and the test(validation) set uses 20%.\n",
        "\n",
        "The following image shows how a model is trained on 80% of the data and then validated against the remaining 20%.\n",
        "\n",
        "![Training and Validation](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_1_train_val.png \"Training and Validation\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "hidden": true,
        "id": "OyecvXt2lIrO",
        "outputId": "2310ab1f-5d0f-49c6-8b30-62d04ed63b10"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "path = \"/data\" #data file can be dowloaded from the link https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "filename = os.path.join(path,\"iris.csv\") #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data\n",
        "df = pd.read_csv(filename,na_values=['NA','?'])\n",
        "\n",
        "df[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "hidden": true,
        "id": "GtZC4PaBlIrP",
        "outputId": "5ff6f2a9-4f24-4569-939b-ec0779b2671f"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['encoded_species'] = le.fit_transform(df['species'])\n",
        "\n",
        "df[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "zKdX_HY4lIrP"
      },
      "outputs": [],
      "source": [
        "# Split into train/test\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']], df['encoded_species'], test_size=0.25, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "0ifqZo0klIrP",
        "outputId": "dc454beb-cd26-40ca-d715-55c0de38b31c"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "0HA81BKklIrQ",
        "outputId": "d2ba364a-4b67-4e16-e89b-9422b5277a5a"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "FNq6PVOZlIrR",
        "outputId": "2050d715-3799-4a51-ad73-5cc96af54d0a"
      },
      "outputs": [],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "S02fuqxRlIrS",
        "outputId": "5417cb3b-9106-4dce-92ac-88e5fec26dc8"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "LQuLLhQZlIrS"
      },
      "source": [
        "# Aggregation\n",
        "\n",
        "Data aggregation is a preprocessing task where the values of two or more objects are combined into a single object. The motivation for aggregation includes (1) reducing the size of data to be processed, (2) changing the granularity of analysis (from fine-scale to coarser-scale), and (3) improving the stability of the data.\n",
        "\n",
        "In the example below, we will use the daily precipitation time series data for a weather station located at Detroit Metro Airport. The raw data was obtained from the Climate Data Online website (https://www.ncdc.noaa.gov/cdo-web/). The daily precipitation time series will be compared against its monthly values.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "The code below will load the precipitation time series data and draw a line plot of its daily time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "hidden": true,
        "id": "O5zjqxb6lIrT",
        "outputId": "3d51e536-c5e9-41c8-a99e-15bfe9997cae",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "daily = pd.read_csv('DTW_prec.csv', header='infer') #The file is available to download from canvas in path Files --> Lab Help --> Labs\n",
        "daily.index = pd.to_datetime(daily['DATE'])\n",
        "daily = daily['PRCP']\n",
        "ax = daily.plot(kind='line',figsize=(15,3))\n",
        "ax.set_title('Daily Precipitation (variance = %.4f)' % (daily.var()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "g8QeGlVVlIrT",
        "outputId": "37f5cd84-f50b-4e67-9cba-544a0fc23687"
      },
      "outputs": [],
      "source": [
        "daily"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "SsMLVvSxlIrT"
      },
      "source": [
        "Observe that the daily time series appear to be quite chaotic and varies significantly from one time step to another. The time series can be grouped and aggregated by month to obtain the total monthly precipitation values. The resulting time series appears to vary more smoothly compared to the daily time series.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "hidden": true,
        "id": "wCbqWYQjlIrU",
        "outputId": "4649e700-9915-4706-af72-5b8615438332"
      },
      "outputs": [],
      "source": [
        "monthly = daily.groupby(pd.Grouper(freq='M')).sum()\n",
        "ax = monthly.plot(kind='line',figsize=(15,3))\n",
        "ax.set_title('Monthly Precipitation (variance = %.4f)' % (monthly.var()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "r6kIyVw1lIrU"
      },
      "source": [
        "In the example below, the daily precipitation time series are grouped and aggregated by year to obtain the annual precipitation values.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "hidden": true,
        "id": "XMXCiZ1clIrV",
        "outputId": "bb77e8a4-0d70-43c2-ae72-3b2228b61459"
      },
      "outputs": [],
      "source": [
        "annual = daily.groupby(pd.Grouper(freq='Y')).sum()\n",
        "ax = annual.plot(kind='line',figsize=(15,3))\n",
        "ax.set_title('Annual Precipitation (variance = %.4f)' % (annual.var()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "sZZEOFfplIrV"
      },
      "source": [
        "# Sampling\n",
        "\n",
        "Sampling is an approach commonly used to facilitate (1) data reduction for exploratory data analysis and scaling up algorithms to big data applications and (2) quantifying uncertainties due to varying data distributions. There are various methods available for data sampling, such as sampling without replacement, where each selected instance is removed from the dataset, and sampling with replacement, where each selected instance is not removed, thus allowing it to be selected more than once in the sample.\n",
        "\n",
        "In the example below, we will apply sampling with replacement and without replacement to the breast cancer dataset obtained from the UCI machine learning repository.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**\n",
        "\n",
        "We initially display the first five records of the table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "hidden": true,
        "id": "AT6H_AFFlIra",
        "outputId": "4f8d6268-96a4-4ffc-efd2-f63996d7d85d"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "mmEFeUuPlIrb"
      },
      "source": [
        "In the following code, a sample of size 3 is randomly selected (without replacement) from the original data.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "hidden": true,
        "id": "riqC9d64lIrc",
        "outputId": "9d03ed17-9e5a-42c6-f5b7-ef679ae61290"
      },
      "outputs": [],
      "source": [
        "sample = data.sample(n=3)\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "iSJ3gG6YlIrd"
      },
      "source": [
        "In the next example, we randomly select 1% of the data (without replacement) and display the selected samples. The random_state argument of the function specifies the seed value of the random number generator.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "hidden": true,
        "id": "pD6vPopUlIrd",
        "outputId": "82313f3e-6cd0-4509-e400-4365795b9779"
      },
      "outputs": [],
      "source": [
        "sample = data.sample(frac=0.01, random_state=1)\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "M0UdheEelIre"
      },
      "source": [
        "Finally, we perform a sampling with replacement to create a sample whose size is equal to 1% of the entire data. You should be able to observe duplicate instances in the sample by increasing the sample size.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "hidden": true,
        "id": "rWy8unBWlIre",
        "outputId": "4ada3ebe-3dfe-43b1-ec10-a78c4aa02899"
      },
      "outputs": [],
      "source": [
        "sample = data.sample(frac=0.01, replace=True, random_state=1)\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Sjhj2AGolIre"
      },
      "source": [
        "# Discretization\n",
        "\n",
        "Discretization is a data preprocessing step that is often used to transform a continuous-valued attribute to a categorical attribute. The example below illustrates two simple but widely-used unsupervised discretization methods (equal width and equal depth) applied to the 'Clump Thickness' attribute of the breast cancer dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "bZfpuJdJlIrf"
      },
      "source": [
        "First, we plot a histogram that shows the distribution of the attribute values. The value_counts() function can also be applied to count the frequency of each attribute value.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "hidden": true,
        "id": "mQm9JqhLlIrf",
        "outputId": "e1436c13-6774-4c78-933b-b027c8e239cf"
      },
      "outputs": [],
      "source": [
        "data['Clump Thickness'].hist(bins=10)\n",
        "data['Clump Thickness'].value_counts(sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "eXk2L0MolIrg"
      },
      "source": [
        "For the equal width method, we can apply the cut() function to discretize the attribute into 4 bins of similar interval widths. The value_counts() function can be used to determine the number of instances in each bin.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "i7ufWStqlIrg",
        "outputId": "66108ef9-bd62-4961-907e-ad5b73c81cdc"
      },
      "outputs": [],
      "source": [
        "bins = pd.cut(data['Clump Thickness'],4)\n",
        "bins.value_counts(sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "m0-7BqmYlIrh"
      },
      "source": [
        "For the equal frequency method, the qcut() function can be used to partition the values into 4 bins such that each bin has nearly the same number of instances.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "MFfUxMP8lIrh",
        "outputId": "fb85448c-d9db-4586-c8d1-4f033c3341af"
      },
      "outputs": [],
      "source": [
        "bins = pd.qcut(data['Clump Thickness'],4)\n",
        "bins.value_counts(sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "5ZnfkACwlIri"
      },
      "source": [
        "# Principal Component Analysis\n",
        "\n",
        "Principal component analysis (PCA) is a classical method for reducing the number of attributes in the data by projecting the data from its original high-dimensional space into a lower-dimensional space. The new attributes (also known as components) created by PCA have the following properties: (1) they are linear combinations of the original attributes, (2) they are orthogonal (perpendicular) to each other, and (3) they capture the maximum amount of variation in the data.\n",
        "\n",
        "The example below illustrates the application of PCA to an image dataset. There are 16 RGB files, each of which has a size of 111 x 111 pixels. The example code below will read each image file and convert the RGB image into a 111 x 111 x 3 = 36963 feature values. This will create a data matrix of size 16 x 36963.    \n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "hidden": true,
        "id": "wHrrXTxblIri",
        "outputId": "9c1618d1-69a8-4339-9c1d-4f402791c506"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "\n",
        "numImages = 16\n",
        "fig = plt.figure(figsize=(7,7))\n",
        "imgData = np.zeros(shape=(numImages,36963))\n",
        "\n",
        "for i in range(1,numImages+1):\n",
        "    filename = 'pics/Picture'+str(i)+'.jpg' #The file is available to download from canvas in path Files --> Lab Help --> Labs\n",
        "    img = mpimg.imread(filename)\n",
        "    ax = fig.add_subplot(4,4,i)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    ax.set_title(str(i))\n",
        "    imgData[i-1] = np.array(img.flatten()).reshape(1,img.shape[0]*img.shape[1]*img.shape[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "A289rZ3ClIri"
      },
      "source": [
        "Using PCA, the data matrix is projected to its first two principal components. The projected values of the original image data are stored in a pandas DataFrame object named projected.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "hidden": true,
        "id": "S2Eo_i3ylIrj",
        "outputId": "82ca9608-59fa-4dab-d182-ba8e8ff57949"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "numComponents = 2\n",
        "pca = PCA(n_components=numComponents)\n",
        "pca.fit(imgData)\n",
        "\n",
        "projected = pca.transform(imgData)\n",
        "projected = pd.DataFrame(projected,columns=['pc1','pc2'],index=range(1,numImages+1))\n",
        "projected['food'] = ['burger', 'burger','burger','burger','drink','drink','drink','drink',\n",
        "                      'pasta', 'pasta', 'pasta', 'pasta', 'chicken', 'chicken', 'chicken', 'chicken']\n",
        "projected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "5ThFtEGblIrk"
      },
      "source": [
        "Finally, we draw a scatter plot to display the projected values. Observe that the images of burgers, drinks, and pastas  are all projected to the same region. However, the images for fried chicken (shown as black squares in the diagram) are harder to discriminate.\n",
        "\n",
        "**<font color=\"red\">Code:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "hidden": true,
        "id": "yARfWnzFlIrk",
        "outputId": "9711a85f-0385-483f-bc81-84a9f3a60c81"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "colors = {'burger':'b', 'drink':'r', 'pasta':'g', 'chicken':'k'}\n",
        "markerTypes = {'burger':'+', 'drink':'x', 'pasta':'o', 'chicken':'s'}\n",
        "\n",
        "for foodType in markerTypes:\n",
        "    d = projected[projected['food']==foodType]\n",
        "    plt.scatter(d['pc1'],d['pc2'],c=colors[foodType],s=60,marker=markerTypes[foodType])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyb37q3ojzLw"
      },
      "source": [
        "### Feature Selection Techniques\n",
        "The goal of feature selection techniques in machine learning is to find the best set of features that allows one to build optimized models of studied phenomena.\n",
        "\n",
        "### Information Gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "cMloakGsj1ao",
        "outputId": "cbcb5b99-218b-499c-f59b-b4e5470f3438"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "df = pd.read_csv('Admission_Predict_Ver1.1.csv') #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data --> Linear_Regression_data\n",
        "X = df.iloc[:,1:-1]\n",
        "Y = df.iloc[:,-1]\n",
        "importances = mutual_info_regression(X, Y)\n",
        "feat_importances = pd.Series(importances,X.columns)\n",
        "feat_importances.plot(kind='barh',color = 'teal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47p1CyvHoLJ3"
      },
      "source": [
        "### Chi-square Test\n",
        "The Chi-square test is used for categorical features in a dataset. We calculate Chi-square between each feature and the target and select the desired number of features with the best Chi-square scores. In order to correctly apply the chi-squared to test the relation between various features in the dataset and the target variable, the following conditions have to be met: the variables have to be categorical, sampled independently, and values should have an expected frequency greater than 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iop-bviGoRu1",
        "outputId": "18fa7904-634f-48b0-dc9b-fd0f01c5d7fa"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_Cat = X.astype(int)\n",
        "le = LabelEncoder()\n",
        "chi2_features = SelectKBest(chi2, k = 3)\n",
        "Y = le.fit_transform(Y)\n",
        "X_kbest_features = chi2_features.fit_transform(X_Cat,Y)\n",
        "\n",
        "print('Original feature number:', X_Cat.shape[1])\n",
        "print('Reduced feature number: ',X_kbest_features.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyUclgkBqx8J"
      },
      "source": [
        "### Correlation Coefficient\n",
        "Correlation is a measure of the linear relationship between 2 or more variables. Through correlation, we can predict one variable from the other. The logic behind using correlation for feature selection is that good variables correlate highly with the target. Furthermore, variables should be correlated with the target but uncorrelated among themselves.\n",
        "\n",
        "If two variables are correlated, we can predict one from the other. Therefore, if two features are correlated, the model only needs one, as the second does not add additional information. We will use the Pearson Correlation here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "-hidpHM2q4iL",
        "outputId": "945b8df1-93cd-4b9b-978c-b77c2e785d2d"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "cor = df.corr()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cor,annot= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R76WH0b2sr3V"
      },
      "source": [
        "### Variance Threshold\n",
        "\n",
        "The variance threshold is a simple baseline approach to feature selection. It removes all features whose variance doesnt meet some threshold. By default, it removes all zero-variance features, i.e., features with the same value in all samples. We assume that features with a higher variance may contain more useful information, but note that we are not taking the relationship between feature variables or feature and target variables into account, which is one of the drawbacks of filter methods.\n",
        "\n",
        "The get_support returns a Boolean vector where True means the variable does not have zero variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIxCdwQQsE4r",
        "outputId": "4522d2a5-01bf-4577-8fac-f06605ff7435"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "X = globals()[\"X\"]\n",
        "\n",
        "\n",
        "v_threshold = VarianceThreshold(threshold = 0)\n",
        "v_threshold.fit(X)\n",
        "v_threshold.get_support()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xenL89o0s857"
      },
      "source": [
        "### Mean Absolute Difference (MAD)\n",
        "The mean absolute difference (MAD) computes the absolute difference from the mean value. The main difference between the variance and MAD measures is the absence of the square in the latter. The MAD, like the variance, is also a scaled variant. This means that the higher the MAD, the higher the discriminatory power."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "-ejHs5SetDyw",
        "outputId": "75751548-60f8-4903-934e-9f4a3b94a597"
      },
      "outputs": [],
      "source": [
        "mean_abs_diff = np.sum(np.abs(X -np.mean(X, axis=0)), axis=0)/X.shape[0]\n",
        "\n",
        "plt.bar(np.arange(X.shape[1]),mean_abs_diff,color = 'teal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQyrcTb0dvRB"
      },
      "source": [
        "## Backward Elimination Techniques\n",
        "## Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jnW4cKqcdjfW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing as prepr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ420jfIe3ke"
      },
      "source": [
        "### Import dataset and do necessary changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHb7PSIheHzc",
        "outputId": "3416fd2c-ce49-4aa9-e98a-a3a641915b93"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Admission_Predict_Ver1.1.csv') #The file is available to download from canvas in path Files --> Lab Help --> Labs --> data --> Linear_Regression_data\n",
        "print('Shape:{}'.format(df.shape))\n",
        "print(df.head(10))\n",
        "print(df.describe())\n",
        "df.columns = [x.replace(' ', '').replace('.', '').lower() for x in list(df)] #converts columnnames to lower single words\n",
        "del df['serialno']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "ZhYLfTPie-OV",
        "outputId": "d11f5dcb-ce87-45d3-a27b-dd36294521ed"
      },
      "outputs": [],
      "source": [
        "df.boxplot(showbox=True, figsize=(10,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYu3R2CbfA81"
      },
      "source": [
        "### Standardizing the entire dataset using Min-Max scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG2ObXwWfG1z",
        "outputId": "65155638-9c9e-4174-ca58-3c56905e7153"
      },
      "outputs": [],
      "source": [
        "cols = list(df)\n",
        "scaler = prepr.MinMaxScaler()\n",
        "scaled_df = scaler.fit_transform(df)\n",
        "scaled_df = pd.DataFrame(scaled_df, columns=cols)\n",
        "print(scaled_df.head(10))\n",
        "print(scaled_df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDTVtk_cfLHr"
      },
      "source": [
        "### Pairplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhhWF-mVfPt-"
      },
      "source": [
        "This is a scatter plot of all the attributes on both x and y axes. 'chanceofadmit' is the dependent variable and the plot clearly shows that there are few attributes that have a linear relation with the dependent attribute. So we can move ahead with linear regression.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N2R3E1l0fMKS",
        "outputId": "cd1f37a0-7925-429b-9e9b-a95c983ca625"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(scaled_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqrrdj4wfaPc"
      },
      "source": [
        "#### Creating X and Y for the linear regression equation (Y = a  + $X_{1}$ + $X_{2}$ + ... + $X_{n}$) where Y is the dependent variable and Xs are the independent variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EXdPX__bfdkc"
      },
      "outputs": [],
      "source": [
        "cols = list(scaled_df)\n",
        "X = scaled_df.iloc[:, :-1]\n",
        "y = scaled_df[cols[-1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Equ85GCGfhbF"
      },
      "source": [
        "### Using statsmodels provided Linear Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD2ubwE5flJu"
      },
      "source": [
        "OLS is the function used to create a linear model. This model defines the linear regression formula as\n",
        "Y = $aX_{0}$ + $X_{1}$ + $X_{2}$ + ... + $X_{n}$.\n",
        "\n",
        "So create a new attribute with all ones and append it to the start of the dataframe. This will serve as $X_{0}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26aBcRAHfl-d",
        "outputId": "5c42c787-e0d6-4c17-912d-cf3413ed1d88"
      },
      "outputs": [],
      "source": [
        "X = np.append(arr=np.ones([len(scaled_df.index), 1]).astype(int), values=X, axis=1)\n",
        "options = X[:, [0, 1, 2, 3, 4, 5, 6, 7]]\n",
        "lm_be = sm.OLS(endog=y, exog=options).fit()\n",
        "print(lm_be.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "v6TVd-hmf2GR",
        "outputId": "97391c63-375c-4b7c-ea7c-12768dcca83a"
      },
      "outputs": [],
      "source": [
        "# Remove attribute 4 (sop) as it has the highest p-value and rewrite the formula\n",
        "options= X[:, [0, 1, 2, 3, 5, 6, 7]]\n",
        "lm_be = sm.OLS(endog=y, exog=options).fit()\n",
        "lm_be.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "pf6dVT2wf5LD",
        "outputId": "3b9142db-a8ab-4527-9349-467e18c03240"
      },
      "outputs": [],
      "source": [
        "# Remove attribute 3 (universityrating) as it has the highest p-value and rewrite the formula\n",
        "options = X[:, [0, 1, 2, 5, 6, 7]]\n",
        "lm_be = sm.OLS(endog=y, exog=options).fit()\n",
        "lm_be.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYfAc_Trf-p8"
      },
      "source": [
        "### Create train and test set from the attributes that are not eliminated by backward elimination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u75uVXqrgBkn"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(options, y, test_size=0.2, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXO5rbgpgD2f"
      },
      "source": [
        "### Create a regular Linear Regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0DHCd_1WgHk3"
      },
      "outputs": [],
      "source": [
        "lm = LinearRegression().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92PvykEYgLKN"
      },
      "source": [
        "### Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oFZubMTugL34"
      },
      "outputs": [],
      "source": [
        "#Predict\n",
        "y_pred = lm.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD7cfd-kgNa2"
      },
      "source": [
        "### Display Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OApjeXtgPCD",
        "outputId": "863acc8c-09e3-41cf-c82c-e20977df77fe"
      },
      "outputs": [],
      "source": [
        "final_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "print(final_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW1xftAMgWV1"
      },
      "source": [
        "### Calculate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCmBc5jLgYby",
        "outputId": "c5133895-8330-498f-ed1b-bc82ccb6738f"
      },
      "outputs": [],
      "source": [
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
        "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
