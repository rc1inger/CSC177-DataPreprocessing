{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552c891b",
   "metadata": {},
   "source": [
    "# ID3 Decision Tree Analysis \n",
    "\n",
    "This notebook demonstrates the application of the ID3 algorithm to classify a dataset based on attributes: color, shape, and size. We will also explore the implications of adding a new attribute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46866178",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset consists of the following attributes:\n",
    "\n",
    "- **Color**\n",
    "- **Shape**\n",
    "- **Size**\n",
    "- **Class** (target attribute)\n",
    "\n",
    "| Color | Shape  | Size  | Class |\n",
    "|-------|--------|-------|-------|\n",
    "| Red   | Square | Big   | +     |\n",
    "| Blue  | Square | Big   | +     |\n",
    "| Red   | Round  | Small | -     |\n",
    "| Green | Square | Small | -     |\n",
    "| Red   | Round  | Big   | +     |\n",
    "| Green | Round  | Big   | -     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667f5b79",
   "metadata": {},
   "source": [
    "## Step 1: Initial Entropy Calculation\n",
    "\n",
    "The initial entropy of the dataset is calculated as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e347612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the distribution of classes\n",
    "num_positive = 3\n",
    "num_negative = 3\n",
    "total_count = num_positive + num_negative\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(positive_count, negative_count):\n",
    "    prob_positive = positive_count / (positive_count + negative_count)\n",
    "    prob_negative = negative_count / (positive_count + negative_count)\n",
    "    # Calculate entropy if both probabilities are greater than zero\n",
    "    return - (prob_positive * np.log2(prob_positive) + prob_negative * np.log2(prob_negative)) if (prob_positive > 0 and prob_negative > 0) else 0\n",
    "\n",
    "# Calculate initial entropy based on class distribution\n",
    "initial_entropy_value = calculate_entropy(num_positive, num_negative)\n",
    "initial_entropy_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dde2db",
   "metadata": {},
   "source": [
    "## Step 2: Information Gain Calculation\n",
    "\n",
    "We will calculate the entropy and information gain for each attribute: color, shape, and size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1b8db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5408520829727552, 0.08170416594551044, 0.4591479170272448)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating entropy for different attributes\n",
    "\n",
    "# Function to compute average entropy for an attribute\n",
    "def compute_average_entropy(attribute_values, target_values):\n",
    "    unique_vals = set(attribute_values)\n",
    "    total_count = len(attribute_values)\n",
    "    average_entropy = 0\n",
    "    \n",
    "    for val in unique_vals:\n",
    "        pos_count = sum(1 for i in range(total_count) if attribute_values[i] == val and target_values[i] == '+')\n",
    "        neg_count = sum(1 for i in range(total_count) if attribute_values[i] == val and target_values[i] == '-')\n",
    "        # Update average entropy with the weighted entropy of the current value\n",
    "        average_entropy += (pos_count + neg_count) / total_count * entropy(pos_count, neg_count)\n",
    "    \n",
    "    return average_entropy\n",
    "\n",
    "# Data setup\n",
    "colors = ['red', 'blue', 'red', 'green', 'red', 'green']\n",
    "shapes = ['square', 'square', 'round', 'square', 'round', 'round']\n",
    "sizes = ['big', 'big', 'small', 'small', 'big', 'big']\n",
    "classes = ['+', '+', '-', '-', '+', '-']\n",
    "\n",
    "# Calculate initial entropy based on the overall class distribution\n",
    "initial_entropy_value = entropy(num_positive, num_negative)\n",
    "\n",
    "# Calculate information gain for each attribute\n",
    "# For color\n",
    "color_entropy_value = compute_average_entropy(colors, classes)\n",
    "color_information_gain = initial_entropy_value - color_entropy_value\n",
    "\n",
    "# For shape\n",
    "shape_entropy_value = compute_average_entropy(shapes, classes)\n",
    "shape_information_gain = initial_entropy_value - shape_entropy_value\n",
    "\n",
    "# For size\n",
    "size_entropy_value = compute_average_entropy(sizes, classes)\n",
    "size_information_gain = initial_entropy_value - size_entropy_value\n",
    "\n",
    "(color_information_gain, shape_information_gain, size_information_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b65dfe",
   "metadata": {},
   "source": [
    "## Step 3: Best Attribute Selection\n",
    "\n",
    "The attribute with the highest information gain will be chosen as the first splitting attribute. In this case, the attribute **Color** has the highest gain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a64de",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "The resulting decision tree based on the attribute **Color** is as follows:\n",
    "\n",
    "- **Color**\n",
    "  - **Red**: Class +\n",
    "  - **Blue**: Class +\n",
    "  - **Green**: Class -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0936c9",
   "metadata": {},
   "source": [
    "## Step 4: Impact of Adding a New Attribute\n",
    "\n",
    "If we add a new attribute, such as **Pattern of Shirt**, with values \"checked,\" \"striped,\" and \"solid,\" the decision tree may change significantly. \n",
    "\n",
    "### Possible Changes:\n",
    "- New splits based on the new attribute.\n",
    "- Potential revision of existing nodes if the new attribute offers better classification.\n",
    "- Increased complexity or improved accuracy of the model.\n",
    "\n",
    "### Consequences of Missing the New Attribute\n",
    "If a data scientist misses this attribute, it could lead to:\n",
    "- Inaccurate predictions.\n",
    "- Financial impacts due to misguided production decisions.\n",
    "- Surprising findings if the attribute is later discovered, which could influence strategic decisions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
